import argparse
import torch
from models.llm import generate_output
from blake3 import blake3
from zk.circom_runner import write_input_json, generate_proof

# 1. –ê—Ä–≥—É–º–µ–Ω—Ç–∏ –∑ –∫–æ–º–∞–Ω–¥–Ω–æ–≥–æ —Ä—è–¥–∫–∞
parser = argparse.ArgumentParser()
parser.add_argument("--prompt", type=str, default="What is privacy-preserving AI?")
args = parser.parse_args()
prompt = args.prompt

# 2. –ü—Ä–∏—Å—Ç—Ä—ñ–π
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"\nüñ•Ô∏è  Using device: {device}")

# 3. –í–∏–≤—ñ–¥ LLM
output = generate_output(prompt)

# 4. Digest (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ª–∏—à–µ –ø–µ—Ä—à—ñ 4 –±–∞–π—Ç–∏ –¥–ª—è Circom-—Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ)
combined = prompt + output
digest_bytes = blake3(combined.encode()).digest()[:4]
digest_int = int.from_bytes(digest_bytes, byteorder="big")

# 5. –°—Ç–≤–æ—Ä—é—î–º–æ input.json —ñ –≥–µ–Ω–µ—Ä—É—î–º–æ zk-proof
write_input_json(expected=digest_int, actual=digest_int)

# 6. –ì–µ–Ω–µ—Ä—É—î–º–æ –¥–æ–∫–∞–∑ —ñ –≤–µ—Ä–∏—Ñ—ñ–∫—É—î–º–æ
is_valid = generate_proof()

# 7. –í–∏–≤—ñ–¥
print("\nüß† Prompt:", prompt)
print("üí¨ Output:", output)
print("üîê Digest (int):", digest_int)
print("‚úÖ Proof verified. Output is valid." if is_valid else "‚ùå Invalid proof. Output rejected.")
